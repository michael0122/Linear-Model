---
title: "linear model from Web"
author: "Michael Abdalla"
date: "Put semester and year"
output:
   html_document:
         toc: true
         toc_depth: 5
        
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Read about the data from the website where it is staged.  Then form three regression models; Model1 is SIMS~ARM, Model2 is SIMS~GRIP, and Model3 is SIMS~ARM+GRIP. For each model find a 95% prediction interval of SIMS given a value of 94  for GRIP and 88 for ARM. Compare Model1 with Model3 using anova. Write it up in a markdown document, push the project up to your github account and submit it back to canvas as link. 

 


```{r include=FALSE}
require(tidyverse)
require(tigerstats)
require(rgl)
require(knitr)

```

```{r}
data <- read.csv(file="https://onlinestatbook.com/case_studies_rvls/physical_strength/data.txt",sep="",header=TRUE)  

```

## Model 1 SIM~ARMS



### scatterplot
```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=ARM))
```

```{r}
basicNN + geom_point()
```

the plot shows there is a positive linear correlation as we have here the sims shown on the y-axis and arm shown on the x-axis 


### Numerical results

```{r}
cor(SIMS~ARM,data=data)
```
the number that the is shown is 0.68 which is a positive number and that indicates that the line will travel upward toward the right.

### Inferential  (Build model.1)

  
```{r}
model.1 <- lm(SIMS~ARM,data=data)
summary.lm(model.1)
```
The evaluation for the line that fits this is SIMS is equal to `r round(summary(model.1)$coefficients[1],3)` +`r round(summary(model.1)$coefficients[2],3)` * ARM 
the formula needed is y = mx + b to create the line.

#### Predict at target point

```{r}
newdata = data.frame(GRIP = 94, ARM = 88)
predict(model.1, newdata, interval = "prediction")
```
this is a prediction interval. how far does one point vary from the other if you take .7 away from 3.13, you'd end up approximately 2.3.

#### scatterplot with model fit


```{r}
basicNN + geom_point() + geom_smooth(method=lm)
```   

the equation formula is y=mx+b which is SIMS= `r round(summary(model.1)$coefficients[1],3)` +`r round(summary(model.1)$coefficients[2],3)` * ARM

## Model 2 SIM~GRIP


```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=GRIP))
```

```{r}
basicNN + geom_point()
```

### Now add in scatterplot

```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=GRIP))
```

```{r}
basicNN + geom_point()
```

 this scatter plot shows that SIMS is correlated with GRIP  where GRIP increases SIMS also increases .

### Numerical results 

```{r}
cor(SIMS~GRIP,data=data)
```
the correlation here is 0.63 the higher the correlation is the closer the points are to each other. this correlation is bit smaller than the previous correlation between ARM.

### Inferential  (Build model.2)

```{r}
model.2 <- lm(SIMS~GRIP,data=data)
summary.lm(model.2)
```  

the adjusted R- square is `r round(summary(model.2)$adj.r.squared,3)`, previously the number was `r round(summary(model.1)$adj.r.squared,3)` small standard error makes for a successful model. this model is not as good as the model with ARM (model.1) because the standard deviation is larger. notice the difference between the multiple.   

#### predict model.2 at target point

```{r}
predict(model.2, newdata, interval = "prediction")
```

the model predicted a SIMS score of -0.536, where the 95% confidence interval -3.107 to 2.035

#### now add the model fit to our plot for model.2

```{r}
basicNN + geom_point() + geom_smooth(method=lm)
``` 


It looks like that the value of Y intercept would be around 1 as well as the equation formula is y=mx+b which is SIMS= `r round(summary(model.1)$coefficients[1],3)` +`r round(summary(model.1)$coefficients[2],3)` * ARM



## Model 3 SIM~ARM+GRIP

### Numerical results (cor)

```{r}
cor(SIMS~ARM+GRIP,data=data)
```
  
### Inferential  (Build 2-dimentional model.3)

```{r}
model.3 <- lm(SIMS~GRIP+ARM,data=data)
summary.lm(model.3)
```  

GRIP * .02447 + ARM * .037 = SIMS 
the bigger the adjusted R square the bigger the model, the multiple R squared is always a little bit bigger than the adjusted R square. the bigger the adjusted R square the bigger we reduce the errors.  

#### predict model.3 at target point

```{r}
predict(model.3, newdata, interval = "prediction")
```

## Comparing nested models ANOVA Test

### Model.1 vs Model.3

```{r}
anova(model.1,model.3)
```

so the p-value is 0.00000499 these results are unlikely to occur by chance the null hypothesis is rejected in favor of the alternative. the residual degrees for freedom is 145. All the errors together are up to 217. the errors were reduced by 29.45. model number two is a better model than model number 1 because many errors were corrected.  

model.1 and model.3 are nested 

### Model.2 vs Model.3

```{r}
anova(model.2,model.3)
```

the p-value is 0.000000001495 the results are unlikely to occur by any chance. all the independent variables in one model are also in the other models SIMS is a function of ARM. model.2 is nested in model.3, model.1 is nested in model.3 

## Informally compare Model.1 with model.2

```{r}
anova(model.1,model.2)
```

0.467 is the adjusted R squared for SIMS~GRIP.

0.4053 is the adjusted R squared for SIMS~GRIP.

how much are the models are able to guess the average.


